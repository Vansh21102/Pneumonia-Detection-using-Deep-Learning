file mgmt.py is first run on the raw dataset downloaded from kaggle to segregate the data into folders of their respective classes.
the images from various classes are loaded into python using OpenCV and functionalities of the OS libraries of python.
the images are then stored in an array contaiing the pixel values of the image of the dimension image_height X image_width X no. of channels (H,W,C) in case of grayscale images the value of C would be 1.
all the images are resized to a size of 224 X 224 (H X W) having 3 channels, i.e, we have taken the full RGB image for computation.
each sample is appended with its numeric label:
               - bacterial = 2
               - Viral = 1
               - Normal = 0

then before passing the data through the Neural Network, the labels are extracted in a labels array
            - the labels arwe extracted to keep the indexing of the labels same as that of the sample, such that the sample receives the correct label since the index of the sample and the index of the label is the same in their respective arrays, i.e, training_data and               labels respectively.

the images are then passed through a Deep CNN of the following architecture:-

Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 224, 224, 32)      896       
                                                                 
 max_pooling2d (MaxPooling2  (None, 112, 112, 32)      0         
 D)                                                              
                                                                 
 batch_normalization (Batch  (None, 112, 112, 32)      128       
 Normalization)                                                  
                                                                 
 conv2d_1 (Conv2D)           (None, 112, 112, 64)      18496     
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 56, 56, 64)        0         
 g2D)                                                            
                                                                 
 batch_normalization_1 (Bat  (None, 56, 56, 64)        256       
 chNormalization)                                                
                                                                 
 conv2d_2 (Conv2D)           (None, 56, 56, 128)       73856     
                                                                 
 max_pooling2d_2 (MaxPoolin  (None, 28, 28, 128)       0         
 g2D)                                                            
                                                                 
 batch_normalization_2 (Bat  (None, 28, 28, 128)       512       
 chNormalization)                                                
                                                                 
 flatten (Flatten)           (None, 100352)            0         
                                                                 
 dense (Dense)               (None, 128)               12845184  
                                                                 
 dense_1 (Dense)             (None, 3)                 387       
                                                                 
=================================================================
Total params: 12939715 (49.36 MB)
Trainable params: 12939267 (49.36 MB)
Non-trainable params: 448 (1.75 KB)
_________________________________________________________________

input shape = (224,224,3)

(CONV_BLOCK_1)
filters in 1st layer = 32
maxpool window = (2 X 2)
BatchNormalization layer()

(CONV_BLOCK_2)
filters in 2nd layer = 64
maxpool window = (2 X 2)
BatchNormalization layer()

(CONV_BLOCK_3)
filters in 2nd layer = 128
maxpool window = (2 X 2)
BatchNormalization layer()

flatten layer()

dense layer neurons = 128
dense layer neurons = 3 (OUTPUT LAYER)

(MODEL PARAMETERS)
optimizer = Adamax (learning_rate = 0.001)
Loss = sparse_Categorical_crossentropy
performance metric = 'Accuracy'

after training through the entire train data, the model is saved and then called again to be tested on the test data.
